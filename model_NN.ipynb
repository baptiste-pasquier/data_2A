{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/baptiste-pasquier/data_2A/blob/main/model_NN.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import sklearn\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de la base Sentiment140 préprocessée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(\"data\", \"sentiment140\", \"train.bz2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>776119</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2322045880</td>\n",
       "      <td>Wed Jun 24 21:57:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>marnieb</td>\n",
       "      <td>oh happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16560</th>\n",
       "      <td>Negative</td>\n",
       "      <td>1555959571</td>\n",
       "      <td>Sat Apr 18 21:12:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>daveholle</td>\n",
       "      <td>flame lip come phx leave detroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696494</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2253544369</td>\n",
       "      <td>Sat Jun 20 08:20:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>roxykins</td>\n",
       "      <td>idea much bravo tv watch unitl rudely take away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542640</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2200493686</td>\n",
       "      <td>Tue Jun 16 18:58:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>superstarnish</td>\n",
       "      <td>way see gg feelin good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140436</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1977041544</td>\n",
       "      <td>Sat May 30 19:56:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>5mariposa5</td>\n",
       "      <td>doubt miss problem internet tweeking linuxmint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167091</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1980016953</td>\n",
       "      <td>Sun May 31 05:23:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>noupa</td>\n",
       "      <td>hahaha familiar indeed take pic study unizh hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102167</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1970902933</td>\n",
       "      <td>Sat May 30 05:36:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LouisMonaco</td>\n",
       "      <td>mean back ur head bore meant like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549261</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2183277539</td>\n",
       "      <td>Mon Jun 15 14:17:10 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LeeDumond</td>\n",
       "      <td>right great mileage think smileage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579813</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2189986691</td>\n",
       "      <td>Tue Jun 16 01:26:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>allyhulton</td>\n",
       "      <td>oh go long trip good pretty glad home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393204</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2055345310</td>\n",
       "      <td>Sat Jun 06 09:08:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>NeilaRich</td>\n",
       "      <td>aw darn time come one day guess lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          id                          date query_string  \\\n",
       "776119   Negative  2322045880  Wed Jun 24 21:57:57 PDT 2009     NO_QUERY   \n",
       "16560    Negative  1555959571  Sat Apr 18 21:12:03 PDT 2009     NO_QUERY   \n",
       "696494   Negative  2253544369  Sat Jun 20 08:20:50 PDT 2009     NO_QUERY   \n",
       "542640   Negative  2200493686  Tue Jun 16 18:58:38 PDT 2009     NO_QUERY   \n",
       "1140436  Positive  1977041544  Sat May 30 19:56:56 PDT 2009     NO_QUERY   \n",
       "...           ...         ...                           ...          ...   \n",
       "1167091  Positive  1980016953  Sun May 31 05:23:21 PDT 2009     NO_QUERY   \n",
       "1102167  Positive  1970902933  Sat May 30 05:36:17 PDT 2009     NO_QUERY   \n",
       "1549261  Positive  2183277539  Mon Jun 15 14:17:10 PDT 2009     NO_QUERY   \n",
       "1579813  Positive  2189986691  Tue Jun 16 01:26:55 PDT 2009     NO_QUERY   \n",
       "393204   Negative  2055345310  Sat Jun 06 09:08:50 PDT 2009     NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "776119         marnieb                                          oh happen  \n",
       "16560        daveholle                   flame lip come phx leave detroit  \n",
       "696494        roxykins    idea much bravo tv watch unitl rudely take away  \n",
       "542640   superstarnish                             way see gg feelin good  \n",
       "1140436     5mariposa5     doubt miss problem internet tweeking linuxmint  \n",
       "...                ...                                                ...  \n",
       "1167091          noupa  hahaha familiar indeed take pic study unizh hi...  \n",
       "1102167    LouisMonaco                  mean back ur head bore meant like  \n",
       "1549261      LeeDumond                 right great mileage think smileage  \n",
       "1579813     allyhulton              oh go long trip good pretty glad home  \n",
       "393204       NeilaRich                aw darn time come one day guess lol  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(50000, random_state=1234)\n",
    "df.sentiment = df.sentiment.apply(lambda x: 'Negative' if x == 0 else 'Positive')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = df.pop('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
