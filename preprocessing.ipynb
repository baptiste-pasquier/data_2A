{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préprocessing du texte\n",
    "\n",
    "accents, contractions, lowercase, newlines, lemmatization, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(serie, stop_words=True, lemmatization=True):\n",
    "    \n",
    "    # lowercase\n",
    "    serie = serie.map(lambda x: x.lower())   \n",
    "\n",
    "    # remove extra newlines\n",
    "    serie = serie.map(lambda x: re.sub(r'[\\r|\\n|\\r\\n]+', ' ', x))\n",
    "\n",
    "    # remove @tag\n",
    "    serie = serie.map(lambda x: re.sub(r'@[\\S]+','', x))\n",
    "\n",
    "    # remove URL\n",
    "    serie = serie.map(lambda x: re.sub('https?://[\\S]+','', x))\n",
    "    \n",
    "    # remove contractions\n",
    "    serie = serie.map(lambda x: contractions.fix(x).lower())\n",
    "\n",
    "    # remove hashtag and numbers\n",
    "    serie = serie.map(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "\n",
    "    # tokenization\n",
    "    serie = serie.map(word_tokenize)\n",
    "    \n",
    "    if stop_words:        \n",
    "        # remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        serie = serie.map(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    if lemmatization:\n",
    "        # lemmatization    \n",
    "        serie = serie.map(nltk.tag.pos_tag)\n",
    "        serie = serie.map(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        serie = serie.map(lambda x: [wordnet_lemmatizer.lemmatize(word, tag) for (word, tag) in x])\n",
    "\n",
    "    serie = serie.map(lambda x: ' '.join(word for word in x))\n",
    "\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment140\n",
    "## Téléchargement de la base Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "url, destname = 'http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip', 'sentiment140'\n",
    "temporary_location = \"temp\"\n",
    "\n",
    "def download_unzip(url, dirname = tempfile.gettempdir(), destname = \"file\"):\n",
    "    myfile = requests.get(url)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    open(os.path.join(dirname, destname + '.zip'), 'wb').write(myfile.content)\n",
    "    with zipfile.ZipFile(os.path.join(dirname, destname + '.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(dirname, destname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_unzip(url, dirname=temporary_location, destname=destname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = os.path.join(temporary_location, destname, \"training.1600000.processed.noemoticon.csv\")\n",
    "# testfile = os.path.join(temporary_location, destname, \"testdata.manual.2009.06.14.csv\")\n",
    "columns = ['sentiment','id','date','query_string','user','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interviews!  â« http://blip.fm/~8bmta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me for details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date query_string  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009     NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009     NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009     NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "...            ...         ...                           ...          ...   \n",
       "1599995          4  2193601966  Tue Jun 16 08:40:49 PDT 2009     NO_QUERY   \n",
       "1599996          4  2193601969  Tue Jun 16 08:40:49 PDT 2009     NO_QUERY   \n",
       "1599997          4  2193601991  Tue Jun 16 08:40:49 PDT 2009     NO_QUERY   \n",
       "1599998          4  2193602064  Tue Jun 16 08:40:49 PDT 2009     NO_QUERY   \n",
       "1599999          4  2193602129  Tue Jun 16 08:40:50 PDT 2009     NO_QUERY   \n",
       "\n",
       "                    user  \\\n",
       "0        _TheSpecialOne_   \n",
       "1          scotthamilton   \n",
       "2               mattycus   \n",
       "3                ElleCTF   \n",
       "4                 Karoli   \n",
       "...                  ...   \n",
       "1599995  AmandaMarie1028   \n",
       "1599996      TheWDBoards   \n",
       "1599997           bpbabe   \n",
       "1599998     tinydiamondz   \n",
       "1599999   RyanTrevMorris   \n",
       "\n",
       "                                                                                                                        text  \n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1            is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                                  @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                            my whole body feels itchy and like its on fire   \n",
       "4            @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   \n",
       "...                                                                                                                      ...  \n",
       "1599995                                                             Just woke up. Having no school is the best feeling ever   \n",
       "1599996                                       TheWDB.com - Very cool to hear old Walt interviews!  â« http://blip.fm/~8bmta  \n",
       "1599997                                                            Are you ready for your MoJo Makeover? Ask me for details   \n",
       "1599998                                                    Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur   \n",
       "1599999                                                       happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H   \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train data set\n",
    "df = pd.read_csv(trainfile,\n",
    "                 header=None, \n",
    "                 names=columns, \n",
    "                 encoding='latin-1')\n",
    "# df = df.head(1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préprocessing Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\n",
       "3                                                                      my whole body feels itchy and like its on fire \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
       "5                                                                                        @Kwesidei not the whole crew \n",
       "6                                                                                                          Need a hug \n",
       "7                  @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?\n",
       "8                                                                                 @Tatiana_K nope they didn't have it \n",
       "9                                                                                            @twittera que me muera ? "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: False, lemmatization: False, time: 187.9986436367035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that is a bummer you shoulda got david carr of third day to do it d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook by texting it and might cry as a result school today also blah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to save the rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it is not behaving at all i am mad why am i here because i can not see you all over there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hey long time no see yes rains a bit only a bit lol i am fine thanks how is you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nope they did not have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>que me muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                          text\n",
       "0                                     awww that is a bummer you shoulda got david carr of third day to do it d\n",
       "1  is upset that he can not update his facebook by texting it and might cry as a result school today also blah\n",
       "2                                    i dived many times for the ball managed to save the rest go out of bounds\n",
       "3                                                               my whole body feels itchy and like its on fire\n",
       "4                 no it is not behaving at all i am mad why am i here because i can not see you all over there\n",
       "5                                                                                           not the whole crew\n",
       "6                                                                                                   need a hug\n",
       "7                              hey long time no see yes rains a bit only a bit lol i am fine thanks how is you\n",
       "8                                                                                    nope they did not have it\n",
       "9                                                                                                 que me muera"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: False, lemmatization: True, time: 1844.4334332942963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that be a bummer you shoulda get david carr of third day to do it d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be upset that he can not update his facebook by texting it and might cry a a result school today also blah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dive many time for the ball manage to save the rest go out of bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feel itchy and like it on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it be not behave at all i be mad why be i here because i can not see you all over there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hey long time no see yes rain a bit only a bit lol i be fine thanks how be you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nope they do not have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>que me muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         text\n",
       "0                                    awww that be a bummer you shoulda get david carr of third day to do it d\n",
       "1  be upset that he can not update his facebook by texting it and might cry a a result school today also blah\n",
       "2                                       i dive many time for the ball manage to save the rest go out of bound\n",
       "3                                                                my whole body feel itchy and like it on fire\n",
       "4                  no it be not behave at all i be mad why be i here because i can not see you all over there\n",
       "5                                                                                          not the whole crew\n",
       "6                                                                                                  need a hug\n",
       "7                              hey long time no see yes rain a bit only a bit lol i be fine thanks how be you\n",
       "8                                                                                    nope they do not have it\n",
       "9                                                                                                que me muera"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: True, lemmatization: False, time: 200.73877000808716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset update facebook texting might cry result school today also blah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behaving mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hey long time see yes rains bit bit lol fine thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>que muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text\n",
       "0                           awww bummer shoulda got david carr third day\n",
       "1  upset update facebook texting might cry result school today also blah\n",
       "2                      dived many times ball managed save rest go bounds\n",
       "3                                       whole body feels itchy like fire\n",
       "4                                                       behaving mad see\n",
       "5                                                             whole crew\n",
       "6                                                               need hug\n",
       "7                    hey long time see yes rains bit bit lol fine thanks\n",
       "8                                                                   nope\n",
       "9                                                              que muera"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: True, lemmatization: True, time: 1565.0616116523743\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww bummer shoulda get david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset update facebook texting might cry result school today also blah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dive many time ball manage save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behave mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hey long time see yes rain bite bit lol fine thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>que muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text\n",
       "0                           awww bummer shoulda get david carr third day\n",
       "1  upset update facebook texting might cry result school today also blah\n",
       "2                          dive many time ball manage save rest go bound\n",
       "3                                        whole body feel itchy like fire\n",
       "4                                                         behave mad see\n",
       "5                                                             whole crew\n",
       "6                                                               need hug\n",
       "7                    hey long time see yes rain bite bit lol fine thanks\n",
       "8                                                                   nope\n",
       "9                                                              que muera"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for stop_words in [False, True]:\n",
    "    for lemmatization in [False, True]:\n",
    "\n",
    "        dfcopy = df.copy()\n",
    "        a = time.time()\n",
    "        dfcopy.text = text_preprocessing(dfcopy.text, stop_words=stop_words, lemmatization=lemmatization)\n",
    "        dfcopy = dfcopy[dfcopy.text != '']\n",
    "\n",
    "        print(f\"stop_words: {stop_words}, lemmatization: {lemmatization}, time: {time.time() - a}\")\n",
    "        display(dfcopy[['text']].head(10))\n",
    "\n",
    "        file = \"train\"\n",
    "        if stop_words:\n",
    "            file += \"_stop\"\n",
    "        if lemmatization:\n",
    "            file += \"_lemm\"\n",
    "        df.to_pickle(os.path.join(\"data\", \"sentiment140\", file+\".bz2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Twitter webscrappée\n",
    "## Chargement de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e6e499a2c7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"web\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"web_parse.bz2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-2A\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;31m# e.g.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unsupported pickle protocol: 5"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(os.path.join(\"data\", \"web\", \"web_parse.bz2\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtre(text):\n",
    "    lower_text = text.lower()\n",
    "    if \"trumps\" in lower_text:\n",
    "        if \"trump\" in lower_text.replace(\"trumps\", \"\"):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche du mot `trump` dans Twitter fournit aussi des tweets comprenants le mot `trumps` (issu du nom ou verbe `trump`), on supprime donc ces tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2868, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df.search == 'biden') | (df.search == \"trump\") & (df.text.apply(filtre))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Off top of my head...Forgive spelling\\n\\nHarris (CA)\\nORourke (TX)\\nCastro (TX)\\nMoulton (MA)\\nWarren (MA)\\nBiden (DE)\\nSanders (VT)\\nCuomo (NY)\\nGillibrand (NY)\\nKlobuchar (MN)\\nBrown (OH)\\nGabbard (HA)\\nMcAuliffe (VA)\\nLandrieu (LA)\\nBooker (NJ) \\nBloomberg (NY)\\nSchultz (WA)\\nGarcetti (CA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I kinda like Kamala/Beto, with Biden as Chif Of Staff. Just sayin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also Biden to Grassley. Did you know he wrote an entire memoir story of his whole life without once mentioning Anita Hill. Do we think he forgot her?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am anxious to see who can pull us out of this mess Trump has got us into.  It will take a strong willed person with a VP that works beside him like Biden did with Obama.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black people, please don’t trust Joe Biden, he wrote the crime bill(1994) that sent thousands of Black people to prison. He is not good for the Black community.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Question is whether there are more of these guys or never-Biden youngsters in the Dem primary/convincable electorate. The oldsters the FYI vote in heavier numbers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What % of @nytimes profits is driven by spending from Russia, China, and Saudi Arabia? Must be significant firvthen to attack lifelong public servants like Joe Biden. Why don't you apply resources to investigating dark money influence instead of hit pieces on good men?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I REALLY wish Democrats would stop trying to push for Biden as a presidential candidate just because they can't think of anybody more visible.\\n\\nSeriously, Biden is an AWFUL choice for multiple reasons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biden/Obama ticket!!!  @JoeBiden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I will.  But then I voted Hillary.  My Dad (and lots of other Republicans) didn't vote for either.  He would vote Biden (Obama's VP) however.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    text\n",
       "0  Off top of my head...Forgive spelling\\n\\nHarris (CA)\\nORourke (TX)\\nCastro (TX)\\nMoulton (MA)\\nWarren (MA)\\nBiden (DE)\\nSanders (VT)\\nCuomo (NY)\\nGillibrand (NY)\\nKlobuchar (MN)\\nBrown (OH)\\nGabbard (HA)\\nMcAuliffe (VA)\\nLandrieu (LA)\\nBooker (NJ) \\nBloomberg (NY)\\nSchultz (WA)\\nGarcetti (CA)\n",
       "1                                                                                                                                                                                                                                   I kinda like Kamala/Beto, with Biden as Chif Of Staff. Just sayin...\n",
       "2                                                                                                                                                  also Biden to Grassley. Did you know he wrote an entire memoir story of his whole life without once mentioning Anita Hill. Do we think he forgot her?\n",
       "3                                                                                                                            I am anxious to see who can pull us out of this mess Trump has got us into.  It will take a strong willed person with a VP that works beside him like Biden did with Obama.\n",
       "4                                                                                                                                       Black people, please don’t trust Joe Biden, he wrote the crime bill(1994) that sent thousands of Black people to prison. He is not good for the Black community.\n",
       "5                                                                                                                                  Question is whether there are more of these guys or never-Biden youngsters in the Dem primary/convincable electorate. The oldsters the FYI vote in heavier numbers...\n",
       "6                          What % of @nytimes profits is driven by spending from Russia, China, and Saudi Arabia? Must be significant firvthen to attack lifelong public servants like Joe Biden. Why don't you apply resources to investigating dark money influence instead of hit pieces on good men?\n",
       "7                                                                                            I REALLY wish Democrats would stop trying to push for Biden as a presidential candidate just because they can't think of anybody more visible.\\n\\nSeriously, Biden is an AWFUL choice for multiple reasons.\n",
       "8                                                                                                                                                                                                                                                                       Biden/Obama ticket!!!  @JoeBiden\n",
       "9                                                                                                                                                          I will.  But then I voted Hillary.  My Dad (and lots of other Republicans) didn't vote for either.  He would vote Biden (Obama's VP) however."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasqu\\anaconda3\\envs\\data-2A\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "for stop_words in [False, True]:\n",
    "    for lemmatization in [False, True]:\n",
    "\n",
    "        dfcopy = df.copy()\n",
    "        a = time.time()\n",
    "        dfcopy.text = text_preprocessing(dfcopy.text, stop_words=stop_words, lemmatization=lemmatization)\n",
    "        dfcopy = dfcopy[dfcopy.text != '']\n",
    "\n",
    "        print(f\"stop_words: {stop_words}, lemmatization: {lemmatization}, time: {time.time() - a}\")\n",
    "        display(dfcopy[['text']].head(10))\n",
    "\n",
    "        file = \"web\"\n",
    "        if stop_words:\n",
    "            file += \"_stop\"\n",
    "        if lemmatization:\n",
    "            file += \"_lemm\"\n",
    "        df.to_pickle(os.path.join(\"data\", \"web\", file+\".bz2\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
